{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, CuDNN 5105)\n",
      "/opt/conda/envs/altair/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:597: UserWarning: Your CuDNN version is more recent then Theano. If you see problems, try updating Theano or downgrading CuDNN to version 4.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu'\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin/\"\n",
    "#import sys\n",
    "#sys.path.append('/data/fs4/home/bradh/')\n",
    "import theano\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import copy\n",
    "\n",
    "import learningfunctions\n",
    "\n",
    "import blocks\n",
    "from blocks.bricks import Linear, Softmax, Softplus, NDimensionalSoftmax, BatchNormalizedMLP, \\\n",
    "                                Rectifier, Logistic, Tanh, MLP\n",
    "from blocks.bricks.recurrent import GatedRecurrent, LSTM\n",
    "from blocks.bricks.parallel import Fork\n",
    "from blocks.initialization import Constant, IsotropicGaussian, Identity, Uniform\n",
    "from blocks.bricks.cost import BinaryCrossEntropy, CategoricalCrossEntropy\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.roles import PARAMETER\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['this is data', 'we like data', 'once upon a time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = T.tensor4(\"raw_data\")\n",
    "rnn_type = \"gru\" # \"lstm\"\n",
    "orig_dims = 70\n",
    "compressed_dims = 20\n",
    "weight_stdev = 0.2\n",
    "rnn_bias_init = Constant(0.0)\n",
    "rnn_weight_init = IsotropicGaussian(weight_stdev)\n",
    "line_weight_init = IsotropicGaussian(weight_stdev)\n",
    "line_bias = Constant(1.0)\n",
    "learning_rate = 0.0001\n",
    "clip_threshold = 1\n",
    "\n",
    "# TODO add learning rate decay over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4('X')\n",
    "rnnType = 'gru'\n",
    "dimIn = 70\n",
    "dim = 20\n",
    "wtstd = 0.2\n",
    "rnnbias_init = Constant(0.0)\n",
    "rnnwt_init = IsotropicGaussian(wtstd)\n",
    "linewt_init = IsotropicGaussian(wtstd)\n",
    "line_bias = Constant(1.0)\n",
    "learning_rate = 0.0001\n",
    "clippings = 1\n",
    "#ADD lr decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rnnType == 'gru':\n",
    "    rnn = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "fork = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dimIn, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def onestepEnc(X):\n",
    "    data1, data2 = fork.apply(X) \n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc = rnn.apply(data1, data2) \n",
    "    else:\n",
    "        hEnc, _ = rnn.apply(data2)\n",
    "\n",
    "    return hEnc\n",
    "\n",
    "hEnc, _ = theano.scan(onestepEnc, X) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fork.initialize()\n",
    "rnn.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer1Fun = theano.function([X], hEnc, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fakeData = np.random.rand(3,50,1,70).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if rnnType == 'gru':\n",
    "    rnn2 = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn2 = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "fork2 = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "\n",
    "\n",
    "def onestepEnc2(hEnc):\n",
    "    data3, data4 = fork2.apply(hEnc) \n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc2 = rnn2.apply(data3, data4) \n",
    "    else:\n",
    "        hEnc2, _ = rnn2.apply(data4)\n",
    "\n",
    "    return hEnc2, data3\n",
    "\n",
    "[hEnc2, data3], _ = theano.scan(onestepEnc2, hEnc) \n",
    "\n",
    "fork2.initialize()\n",
    "rnn2.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer2Fun = theano.function([X], hEnc2, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if rnnType == 'gru':\n",
    "    rnn3 = GatedRecurrent(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn3 = LSTM(dim=dim, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "fork3 = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dim, output_dims=[dim, dim * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "forkD = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dim, output_dims=[dimIn, dimIn * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "def onestepEnc3(hEnc2):\n",
    "    data5, data6 = fork3.apply(hEnc2) \n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hEnc3 = rnn3.apply(data5, data6) \n",
    "    else:\n",
    "        hEnc3, _ = rnn3.apply(data6)\n",
    "\n",
    "    return hEnc3\n",
    "\n",
    "hEnc3, _ = theano.scan(onestepEnc3, hEnc2) \n",
    "h4decoder = hEnc3[:,-1,:,:].reshape((-1, 1,1,20))\n",
    "\n",
    "h4reshape, _ = forkD.apply(h4decoder)\n",
    "\n",
    "forkD.initialize()\n",
    "fork3.initialize()\n",
    "rnn3.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer3Fun = theano.function([X], h4reshape, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if rnnType == 'gru':\n",
    "    rnn4 = GatedRecurrent(dim=dimIn, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'gru')\n",
    "    dimMultiplier = 2\n",
    "else:\n",
    "    rnn4 = LSTM(dim=dimIn, weights_init = rnnwt_init, biases_init = rnnbias_init, name = 'lstm')\n",
    "    dimMultiplier = 4\n",
    "\n",
    "#TOTHINK: transform before the decoder or after\n",
    "fork4 = Fork(output_names=['linear', 'gates'],\n",
    "            name='fork', input_dim=dimIn, output_dims=[dimIn, dimIn * dimMultiplier], \n",
    "            weights_init = linewt_init, biases_init = line_bias)\n",
    "\n",
    "targets = T.concatenate((h4reshape, X[:,:-1, :,:]), axis=1)\n",
    "\n",
    "def onestepEnc4(targets):\n",
    "    data7, data8 = fork4.apply(targets) \n",
    "\n",
    "    if rnnType == 'gru':\n",
    "        hDec = rnn4.apply(data7, data8) \n",
    "    else:\n",
    "        hDec, _ = rnn4.apply(data8)\n",
    "\n",
    "    return hDec\n",
    "\n",
    "hDec, _ = theano.scan(onestepEnc4, targets) \n",
    "\n",
    "fork4.initialize()\n",
    "rnn4.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer4Fun = theano.function([X], hDec, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decFun = theano.function([X], targets, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predTargets = T.exp(hDec)/T.sum(T.exp(hDec), axis=(3,2), keepdims=True)\n",
    "#precost = -X.squeeze*T.log(predTargets.squeeze()) - (1-X.squeeze())*T.log(1-predTargets.squeeze())\n",
    "\n",
    "#ADDLATER: beam search\n",
    "cost = T.mean(T.sum(T.nnet.categorical_crossentropy(predTargets, X), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling graph you talented soul\n"
     ]
    }
   ],
   "source": [
    "cg = ComputationGraph([cost])\n",
    "params = VariableFilter(roles = [PARAMETER])(cg.variables)\n",
    "\n",
    "###To check gradients for explosion/shrinkage\n",
    "#gradients = T.grad(costClass, paramsClass)\n",
    "#gradients = clip_norms(gradients, clippings)\n",
    "#gradientFun = theano.function([X,Y], gradients, allow_input_downcast=True)\n",
    "\n",
    "learning = learningfunctions.Learning(cost,params,learning_rate,l1=0.,l2=0.,maxnorm=0.,c=clippings)\n",
    "updates = learning.Adam() \n",
    "\n",
    "print('compiling graph you talented soul')\n",
    "classifierTrain = theano.function([X], [cost, predTargets], \n",
    "                                  updates=updates, allow_input_downcast=True)\n",
    "#classifierPredict = theano.function([X], [softoutClass, attEncpred, attContextpred], allow_input_downcast=True)\n",
    "classifierPredict = theano.function([X], predTargets, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test.txt', 'r') as f:\n",
    "    charDict2 = f.readlines()[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charDict2 = charDict2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charDict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'\\\\' in charDict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r'234\\55'[3] in charDict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Altair",
   "language": "python",
   "name": "altair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
